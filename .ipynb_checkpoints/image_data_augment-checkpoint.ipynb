{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T09:29:57.524473Z",
     "start_time": "2019-01-03T09:29:57.514824Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Augments images from image directories with corresponding xml labels from xml directories,\n",
    "outputs to the same input image directories\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T04:17:20.092165Z",
     "start_time": "2019-01-15T04:17:16.938895Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import imgaug as ia\n",
    "import numpy as np\n",
    "import lxml.etree as ET\n",
    "#import xml.etree.ElementTree as ET\n",
    "from imgaug import augmenters as iaa\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-11T10:25:41.147Z"
    }
   },
   "outputs": [],
   "source": [
    "image_directories = [] #array of paths to image directories to augment\n",
    "image_extension = '.jpg'\n",
    "augmentation_factor = 1 #factor of number of original images to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-11T10:25:41.319Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_images(np_img_array, img_dir):\n",
    "    \"\"\"Augments numpy array encoded images and saves them to img dir without overwriting.\"\"\"\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.8, aug)\n",
    "    seq = iaa.Sequential([\n",
    "        #iaa.Sometimes(0.2, iaa.PiecewiseAffine(scale=(0.01, 0.03))),\n",
    "        iaa.SomeOf((0, 3),[\n",
    "            sometimes(iaa.OneOf([iaa.GaussianBlur(sigma=(0.25, 1.25)),\n",
    "                       #iaa.AverageBlur(k=(3, 7)),\n",
    "                       #iaa.MedianBlur(k=(3, 7)),\n",
    "                       iaa.blur.MotionBlur(k=(3, 7)),\n",
    "                       iaa.blur.BilateralBlur(d=(3, 7), sigma_color=250, sigma_space=250)\n",
    "                       ])),\n",
    "              \n",
    "            sometimes(iaa.OneOf([iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.025*255), per_channel=0.15),\n",
    "                       iaa.SaltAndPepper((0.05, 0.15))])),\n",
    "              \n",
    "            iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),\n",
    "              \n",
    "            iaa.OneOf([iaa.ContrastNormalization((0.5, 1.5), per_channel=0.2),\n",
    "                       iaa.GammaContrast(gamma=(0.5, 1.5), per_channel=0.2),\n",
    "                       iaa.SigmoidContrast(gain=(5, 15), cutoff=(0.25,0.75)),\n",
    "                       iaa.LogContrast(gain=(0.5, 1.0), per_channel=0.2),\n",
    "                       iaa.LinearContrast(alpha=(0.5, 1.75), per_channel=0.2),\n",
    "                       iaa.AllChannelsCLAHE(clip_limit=(1,20), per_channel=0.5)\n",
    "                       ]),\n",
    "            iaa.OneOf([\n",
    "                 iaa.Sequential([\n",
    "                     iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "                     iaa.WithChannels(0, iaa.Add((50, 100))),\n",
    "                     iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\")\n",
    "                 ]),\n",
    "                 iaa.Grayscale(alpha=(0.3, 1.0)),\n",
    "                 iaa.Multiply((0.5, 1.5), per_channel=True)\n",
    "                 ])\n",
    "            ], random_order=True),\n",
    "        sometimes(iaa.OneOf([iaa.CoarseDropout((0.2, 0.25), size_percent=(0.001, 0.02), per_channel=0.1),\n",
    "                             iaa.CoarseSaltAndPepper((0.2, 0.25), size_percent=(0.001, 0.02),),\n",
    "                             iaa.Superpixels(p_replace=(0.2, 0.25), n_segments=(128,256))]))\n",
    "    ], random_order=True) # apply augmenters in random order\n",
    "\n",
    "    images_aug = seq.augment_images(np_img_array)\n",
    "    for image in images_aug:\n",
    "        global image_num \n",
    "        image_num += 1\n",
    "        im = Image.fromarray(image)\n",
    "        im.save(join(image_dir, 'aug_img_{}{}'.format(image_num, image_extension)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-11T10:25:41.482Z"
    }
   },
   "outputs": [],
   "source": [
    "for image_dir in image_directories:\n",
    "    image_list = sorted(glob(join(image_dir,'*' + image_extension)))\n",
    "    np_img_array = []\n",
    "    \n",
    "    for image in image_list: \n",
    "        np_image = np.array(Image.open(image))\n",
    "        np_img_array.append(np_image)\n",
    "    image_num = 0\n",
    "    \n",
    "    for cycle in range(augmentation_factor):\n",
    "        print('Image Directory: {} Cycle: {}'.format(image_dir, cycle))\n",
    "        augment_images(np_img_array, image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T04:59:07.124200Z",
     "start_time": "2019-01-15T04:59:07.120083Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '' #directory containing folders of images and xmls in VOC format\n",
    "image_directories = sorted(glob(join(root_dir, '*')))\n",
    "xml_directories = sorted(glob(join(root_dir, '*')))\n",
    "image_extension = '.jpg'\n",
    "augmentation_factor = 5 #factor of number of original images to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T04:59:07.287117Z",
     "start_time": "2019-01-15T04:59:07.277088Z"
    }
   },
   "outputs": [],
   "source": [
    "def edit_xml(bbs, image_filename, xml_output_filename, image_output_filename):\n",
    "    \"\"\"Edits single xml for one image to update augmented bounding box coordinates\n",
    "       Arguments:\n",
    "       bbs: instance of BoundingBoxesOnImage\n",
    "       \"\"\"\n",
    "    xml_filename = image_filename[:-4] + '.xml'\n",
    "    xml_filename = os.path.split(xml_filename)[-1]\n",
    "    xml_filepath = join(xml_dir, xml_filename)\n",
    "    \n",
    "    tree = ET.parse(xml_filepath)\n",
    "    root = tree.getroot()\n",
    "    filename = root.find('filename')\n",
    "    filename.text = os.path.split(image_output_filename)[-1]\n",
    "    path = root.find('path')\n",
    "    path.text = image_output_filename\n",
    "    #remove all current objects to prevent bugs associated with overwriting\n",
    "    for obj in root.findall('object'):\n",
    "        root.remove(obj)\n",
    "    #create new object tag for each bounding box in augmented image\n",
    "    for bb in bbs.bounding_boxes:\n",
    "        obj = ET.SubElement(root, 'object')\n",
    "        name = ET.SubElement(obj, 'name')\n",
    "        name.text = bb.label\n",
    "        pose = ET.SubElement(obj, 'pose')\n",
    "        pose.text = 'Unspecified'\n",
    "        truncated = ET.SubElement(obj, 'truncated')\n",
    "        truncated.text = '0'\n",
    "        difficult = ET.SubElement(obj, 'Difficult')\n",
    "        difficult.text = '0'\n",
    "        bndbox = ET.SubElement(obj, 'bndbox')\n",
    "        xmin = ET.SubElement(bndbox, 'xmin')\n",
    "        xmax = ET.SubElement(bndbox, 'xmax')\n",
    "        ymin = ET.SubElement(bndbox, 'ymin')\n",
    "        ymax = ET.SubElement(bndbox, 'ymax')\n",
    "        xmin.text = str(int(round(bb.x1)))\n",
    "        xmax.text = str(int(round(bb.x2)))\n",
    "        ymin.text = str(int(round(bb.y1)))\n",
    "        ymax.text = str(int(round(bb.y2)))\n",
    "\n",
    "    tree.write(xml_output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T04:59:07.567985Z",
     "start_time": "2019-01-15T04:59:07.565157Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocessor(images, augmenter, parents):\n",
    "    print(augmenter.name)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T04:59:08.074089Z",
     "start_time": "2019-01-15T04:59:08.063399Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_images_and_xmls(image_dir, img_list, xml_list):\n",
    "    np_img_array = []\n",
    "    bbs_on_img_array = [] #array of BoundingBoxesOnImage instances\n",
    "    aug_img_list = [] #list of images with corresponding xml file that can be augmented\n",
    "    for xml in xml_list:\n",
    "        img_filename = xml[:-4] + image_extension\n",
    "        img_filename = os.path.split(img_filename)[-1]\n",
    "        img_path = join(image_dir, img_filename) #get img filename that matches xml filename\n",
    "        if img_path in img_list: #and check it exists\n",
    "            \n",
    "            tree = ET.parse(xml)\n",
    "            root = tree.getroot()\n",
    "            size = root.find('size')\n",
    "            w = int(size.find('width').text)\n",
    "            h = int(size.find('height').text)\n",
    "            boxes = []\n",
    "            for obj in root.findall('object'):\n",
    "                xmlbox = obj.find('bndbox')\n",
    "                label = obj.find('name').text\n",
    "                b = (int(xmlbox.find('xmin').text), int(xmlbox.find('xmax').text), \n",
    "                     int(xmlbox.find('ymin').text), int(xmlbox.find('ymax').text),\n",
    "                     label)\n",
    "                boxes.append(b)\n",
    "            if boxes == []:\n",
    "                continue\n",
    "\n",
    "            bbs_on_img = ia.BoundingBoxesOnImage(\n",
    "                [ia.BoundingBox(x1=box[0], y1=box[2], \n",
    "                                x2=box[1], y2=box[3], label=box[4]) for box in boxes],\n",
    "                shape=(h,w))\n",
    "            bbs_on_img_array.append(bbs_on_img)\n",
    "            \n",
    "            aug_img_list.append(img_path)\n",
    "            np_image = np.asarray(Image.open(img_path))\n",
    "            np_img_array.append(np_image)\n",
    "            \n",
    "        else: #if image does not exist for the xml filename\n",
    "            print('Image not found for xml: ', xml)\n",
    "            continue\n",
    "    return np_img_array, bbs_on_img_array, aug_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T04:59:08.536078Z",
     "start_time": "2019-01-15T04:59:08.526395Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def augment_images_with_bbs(image_dir, xml_dir, np_img_array, bbs_on_img_array, aug_img_list):\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.8, aug)\n",
    "    seq = iaa.Sequential(\n",
    "        [iaa.Fliplr(0.5), \n",
    "         iaa.Affine(\n",
    "            #scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "            #translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "            rotate=(-30, 30),\n",
    "            #shear=(-16, 16),\n",
    "            mode='edge')\n",
    "        ],\n",
    "        # do all of the above augmentations in random order\n",
    "        random_order=True\n",
    "    )\n",
    "    hooks = ia.HooksImages(postprocessor=postprocessor)\n",
    "    assert len(bbs_on_img_array) == len(np_img_array)\n",
    "    seq_det = seq.to_deterministic()\n",
    "    image_aug = seq_det.augment_images(np_img_array, hooks=hooks)\n",
    "    bbs_aug = seq_det.augment_bounding_boxes(bbs_on_img_array)\n",
    "    cleaned_bbs_aug = [] #array of bbs that are not out of image\n",
    "    for i, bb in enumerate(bbs_aug): #bb = bbs on img\n",
    "        cleaned_bbs_aug.append(bb.remove_out_of_image().cut_out_of_image())\n",
    "    assert len(image_aug) == len(cleaned_bbs_aug)\n",
    "    #convert to PIL and save img and xml in respective directories\n",
    "    for count, (image, bbs) in enumerate(zip(image_aug, cleaned_bbs_aug)):\n",
    "        global image_num \n",
    "        image_num += 1\n",
    "        im = Image.fromarray(image)\n",
    "        im.save(join(image_dir, 'aug_img_{}{}'.format(image_num, image_extension)))\n",
    "        edit_xml(bbs, \n",
    "                 aug_img_list[count], \n",
    "                 join(xml_dir, 'aug_img_{}{}'.format(image_num, '.xml')),\n",
    "                 join(image_dir, 'aug_img_{}{}'.format(image_num, image_extension)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T04:59:11.083166Z",
     "start_time": "2019-01-15T04:59:09.025523Z"
    }
   },
   "outputs": [],
   "source": [
    "for image_dir, xml_dir in zip(image_directories, xml_directories):\n",
    "    image_num = 0\n",
    "    img_list = sorted(glob(join(image_dir, '*' + image_extension)))\n",
    "    xml_list = sorted(glob(join(xml_dir, '*.xml')))\n",
    "    np_img_array, bbs_on_img_array, aug_img_list = read_images_and_xmls(image_dir, img_list, xml_list)\n",
    "    for cycle in range(augmentation_factor):\n",
    "        print('Image Directory: {} Cycle: {}'.format(image_dir, cycle))\n",
    "        augment_images_with_bbs(image_dir, xml_dir, np_img_array, bbs_on_img_array, aug_img_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove top quarter of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T10:37:26.744898Z",
     "start_time": "2018-12-20T10:37:26.742058Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os.path import join\n",
    "import keras\n",
    "from glob import glob\n",
    "from keras_preprocessing.image import array_to_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T10:53:47.346498Z",
     "start_time": "2018-12-20T10:49:10.874411Z"
    }
   },
   "outputs": [],
   "source": [
    "img_dir_path = ''\n",
    "output_path = '' \n",
    "for i, img in enumerate(glob(join(img_dir_path, '*.jpg'))):\n",
    "    im = Image.open(img)\n",
    "    arr = img_to_array(im)\n",
    "    idx = int(0.25*arr.shape[0])\n",
    "    arr = arr[idx:]\n",
    "    new_im = array_to_img(arr)\n",
    "    new_im.save(join(output_path, 'image_{}.jpg'.format(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T07:47:23.687706Z",
     "start_time": "2019-01-10T07:47:23.373227Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = ''\n",
    "files = glob(join(root_dir, '**', '*', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T07:48:18.946271Z",
     "start_time": "2019-01-10T07:48:15.843170Z"
    }
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    filename = os.path.split(file)[-1]\n",
    "    if filename[:3] == 'aug':\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T09:09:19.202599Z",
     "start_time": "2019-01-10T08:49:31.732038Z"
    }
   },
   "outputs": [],
   "source": [
    "for image_dir in image_directories:\n",
    "    image_list = sorted(glob(image_dir + '*' + image_extension))\n",
    "    np_img_array = []\n",
    "    \n",
    "    for image in image_list: \n",
    "        np_image = np.array(Image.open(image))\n",
    "        np_img_array.append(np_image)\n",
    "    image_num = 0\n",
    "    \n",
    "    for cycle in range(augmentation_factor):\n",
    "        print('Image Directory: {} Cycle: {}'.format(image_dir, cycle))\n",
    "        test_augment_images(np_img_array, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
